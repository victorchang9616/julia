{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia is fast\n",
    "\n",
    "Very often, benchmarks are used to compare languages.  These benchmarks can lead to long discussions, first as to exactly what is being benchmarked and secondly what explains the differences.  These simple questions can sometimes get more complicated than you at first might imagine.\n",
    "\n",
    "The purpose of this notebook is for you to see a simple benchmark for yourself.  One can read the notebook and see what happened on the author's Macbook Pro with a 4-core Intel Core I5, or run the notebook yourself.\n",
    "\n",
    "(This material began life as a wonderful lecture by Steven Johnson at MIT: https://github.com/stevengj/18S096/blob/master/lectures/lecture1/Boxes-and-registers.ipynb.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of this notebook\n",
    "\n",
    "- Define the sum function\n",
    "- Implementations & benchmarking of sum in...\n",
    "    - C (hand-written)\n",
    "    - C (hand-written with -ffast-math)\n",
    "    - python (built-in)\n",
    "    - python (numpy)\n",
    "    - python (hand-written)\n",
    "    - Julia (built-in)\n",
    "    - Julia (hand-written)\n",
    "    - Julia (hand-written with SIMD)\n",
    "- Summary of benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sum`: An easy enough function to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the  **sum** function `sum(a)`, which computes\n",
    "$$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i,\n",
    "$$\n",
    "where $n$ is the length of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = rand(10^7); # 1D vector of random numbers, uniform on [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000643397143609e6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result is 0.5 * 10^7, since the mean of each entry is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a few ways in a few languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004108 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000643397143609e6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004742 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000643397143609e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004289 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000643397143609e6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro can yield noisy results, so it's not our best choice for benchmarking!\n",
    "\n",
    "Luckily, Julia has a `BenchmarkTools.jl` package to make benchmarking easy and accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `C:\\Users\\Victor\\.julia\\registries\\General`"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [>                                        ]  0.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  0.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  0.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  0.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  0.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  0.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  0.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  1.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  2.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  2.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  2.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=>                                       ]  2.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  2.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  2.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  2.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  2.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  3.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==>                                      ]  4.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  5.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  6.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  7.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  7.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  7.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===>                                     ]  7.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  7.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  7.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  7.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  8.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [====>                                    ]  9.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  10.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.1 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.8 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  11.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  12.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  12.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  12.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====>                                   ]  12.5 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  12.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  12.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  12.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.2 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.3 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.4 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.6 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.7 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  13.9 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  14.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [======>                                  ]  14.1 %"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [========================================>]  1009 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [==============>                          ]  33.8 %>                   ]  50.6 %]  55.7 %.2 %           ]  72.3 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [===================================>     ]  86.0 %4 %.0 %\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Zlib_jll ─────── v1.2.11+11\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OpenSSL_jll ──── v1.1.1+3\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m BenchmarkTools ─ v0.5.0\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Project.toml`\n",
      " \u001b[90m [6e4b80f9]\u001b[39m\u001b[92m + BenchmarkTools v0.5.0\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Manifest.toml`\n",
      " \u001b[90m [6e4b80f9]\u001b[39m\u001b[92m + BenchmarkTools v0.5.0\u001b[39m\n",
      " \u001b[90m [458c3c95]\u001b[39m\u001b[93m ↑ OpenSSL_jll v1.1.1+2 ⇒ v1.1.1+3\u001b[39m\n",
      " \u001b[90m [83775a58]\u001b[39m\u001b[93m ↑ Zlib_jll v1.2.11+10 ⇒ v1.2.11+11\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"BenchmarkTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. The C language\n",
    "\n",
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "The current author does not speak C, so he does not read the cell below, but is happy to know that you can put C code in a Julia session, compile it, and run it. Note that the `\"\"\"` wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m PackageCompiler ─ v1.1.1\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Project.toml`\n",
      " \u001b[90m [9b87118b]\u001b[39m\u001b[92m + PackageCompiler v1.1.1\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Manifest.toml`\n",
      " \u001b[90m [9b87118b]\u001b[39m\u001b[92m + PackageCompiler v1.1.1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"PackageCompiler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling PackageCompiler [9b87118b-4619-50d2-8e1e-99f35a4d4d9d]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using PackageCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant Clib\n"
     ]
    },
    {
     "ename": "Base.IOError",
     "evalue": "IOError: could not spawn `gcc -fPIC -O3 -msse3 -xc -shared -o 'C:\\Users\\Victor\\AppData\\Local\\Temp\\jl_6iDy18PrUJ.dll' -`: no such file or directory (ENOENT)",
     "output_type": "error",
     "traceback": [
      "IOError: could not spawn `gcc -fPIC -O3 -msse3 -xc -shared -o 'C:\\Users\\Victor\\AppData\\Local\\Temp\\jl_6iDy18PrUJ.dll' -`: no such file or directory (ENOENT)",
      "",
      "Stacktrace:",
      " [1] _spawn_primitive(::String, ::Cmd, ::Array{Any,1}) at .\\process.jl:99",
      " [2] #550 at .\\process.jl:112 [inlined]",
      " [3] setup_stdios(::Base.var\"#550#551\"{Cmd}, ::Array{Any,1}) at .\\process.jl:196",
      " [4] _spawn at .\\process.jl:111 [inlined]",
      " [5] open(::Cmd, ::Base.DevNull; write::Bool, read::Bool) at .\\process.jl:374",
      " [6] open(::Cmd, ::String, ::Base.DevNull) at .\\process.jl:343",
      " [7] open at .\\process.jl:338 [inlined]",
      " [8] open(::var\"#13#14\", ::Cmd, ::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at .\\process.jl:391",
      " [9] open(::Function, ::Cmd, ::String) at .\\process.jl:391",
      " [10] top-level scope at In[34]:14"
     ]
    }
   ],
   "source": [
    "using Libdl\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum(a) - sum(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "≈  # alias for the `isapprox` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?isapprox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now benchmark the C code directly from Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "println(\"C: Fastest time was $(minimum(c_bench.times) / 1e6) msec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 0 entries"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dict()  # a \"dictionary\", i.e. an associative array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics # bring in statistical support for standard deviations\n",
    "t = c_bench.times / 1e6 # times in milliseconds\n",
    "m, σ = minimum(t), std(t)\n",
    "\n",
    "histogram(t, bins=500,\n",
    "        xlim=(m - 0.01, m + σ),\n",
    "        xlabel=\"milliseconds\", ylabel=\"count\", label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. C with -ffast-math\n",
    "\n",
    "If we allow C to re-arrange the floating point operations, then it'll vectorize with SIMD (single instruction, multiple data) instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const Clib_fastmath = tempname()   # make a temporary file\n",
    "\n",
    "# The same as above but with a -ffast-math flag added\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -ffast-math -o $(Clib_fastmath * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum_fastmath(X::Array{Float64}) = ccall((\"c_sum\", Clib_fastmath), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_fastmath_bench = @benchmark $c_sum_fastmath($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"C -ffast-math\"] = minimum(c_fastmath_bench.times) / 1e6  # in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Python's built in `sum` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyCall` package provides a Julia interface to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Project.toml`\n",
      " \u001b[90m [438e738f]\u001b[39m\u001b[92m + PyCall v1.91.4\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.add(\"PyCall\")\n",
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mx\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "isapprox(x, y; rtol::Real=atol>0 ? 0 : √eps, atol::Real=0, nans::Bool=false, norm::Function)\n",
       "\\end{verbatim}\n",
       "Inexact equality comparison: \\texttt{true} if \\texttt{norm(x-y) <= max(atol, rtol*max(norm(x), norm(y)))}. The default \\texttt{atol} is zero and the default \\texttt{rtol} depends on the types of \\texttt{x} and \\texttt{y}. The keyword argument \\texttt{nans} determines whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "For real or complex floating-point values, if an \\texttt{atol > 0} is not specified, \\texttt{rtol} defaults to the square root of \\href{@ref}{\\texttt{eps}} of the type of \\texttt{x} or \\texttt{y}, whichever is bigger (least precise). This corresponds to requiring equality of about half of the significand digits. Otherwise, e.g. for integer arguments or if an \\texttt{atol > 0} is supplied, \\texttt{rtol} defaults to zero.\n",
       "\n",
       "\\texttt{x} and \\texttt{y} may also be arrays of numbers, in which case \\texttt{norm} defaults to the usual \\texttt{norm} function in LinearAlgebra, but may be changed by passing a \\texttt{norm::Function} keyword argument. (For numbers, \\texttt{norm} is the same thing as \\texttt{abs}.) When \\texttt{x} and \\texttt{y} are arrays, if \\texttt{norm(x-y)} is not finite (i.e. \\texttt{±Inf} or \\texttt{NaN}), the comparison falls back to checking whether all elements of \\texttt{x} and \\texttt{y} are approximately equal component-wise.\n",
       "\n",
       "The binary operator \\texttt{≈} is equivalent to \\texttt{isapprox} with the default arguments, and \\texttt{x ≉ y} is equivalent to \\texttt{!isapprox(x,y)}.\n",
       "\n",
       "Note that \\texttt{x ≈ 0} (i.e., comparing to zero with the default tolerances) is equivalent to \\texttt{x == 0} since the default \\texttt{atol} is \\texttt{0}.  In such cases, you should either supply an appropriate \\texttt{atol} (or use \\texttt{norm(x) ≤ atol}) or rearrange your code (e.g. use \\texttt{x ≈ y} rather than \\texttt{x - y ≈ 0}).   It is not possible to pick a nonzero \\texttt{atol} automatically because it depends on the overall scaling (the \"units\") of your problem: for example, in \\texttt{x - y ≈ 0}, \\texttt{atol=1e-9} is an absurdly small tolerance if \\texttt{x} is the \\href{https://en.wikipedia.org/wiki/Earth_radius}{radius of the Earth} in meters, but an absurdly large tolerance if \\texttt{x} is the \\href{https://en.wikipedia.org/wiki/Bohr_radius}{radius of a Hydrogen atom} in meters.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> 0.1 ≈ (0.1 - 1e-10)\n",
       "true\n",
       "\n",
       "julia> isapprox(10, 11; atol = 2)\n",
       "true\n",
       "\n",
       "julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\n",
       "true\n",
       "\n",
       "julia> 1e-10 ≈ 0\n",
       "false\n",
       "\n",
       "julia> isapprox(1e-10, 0, atol=1e-8)\n",
       "true\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "isapprox(x, y; rtol::Real=atol>0 ? 0 : √eps, atol::Real=0, nans::Bool=false, norm::Function)\n",
       "```\n",
       "\n",
       "Inexact equality comparison: `true` if `norm(x-y) <= max(atol, rtol*max(norm(x), norm(y)))`. The default `atol` is zero and the default `rtol` depends on the types of `x` and `y`. The keyword argument `nans` determines whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "For real or complex floating-point values, if an `atol > 0` is not specified, `rtol` defaults to the square root of [`eps`](@ref) of the type of `x` or `y`, whichever is bigger (least precise). This corresponds to requiring equality of about half of the significand digits. Otherwise, e.g. for integer arguments or if an `atol > 0` is supplied, `rtol` defaults to zero.\n",
       "\n",
       "`x` and `y` may also be arrays of numbers, in which case `norm` defaults to the usual `norm` function in LinearAlgebra, but may be changed by passing a `norm::Function` keyword argument. (For numbers, `norm` is the same thing as `abs`.) When `x` and `y` are arrays, if `norm(x-y)` is not finite (i.e. `±Inf` or `NaN`), the comparison falls back to checking whether all elements of `x` and `y` are approximately equal component-wise.\n",
       "\n",
       "The binary operator `≈` is equivalent to `isapprox` with the default arguments, and `x ≉ y` is equivalent to `!isapprox(x,y)`.\n",
       "\n",
       "Note that `x ≈ 0` (i.e., comparing to zero with the default tolerances) is equivalent to `x == 0` since the default `atol` is `0`.  In such cases, you should either supply an appropriate `atol` (or use `norm(x) ≤ atol`) or rearrange your code (e.g. use `x ≈ y` rather than `x - y ≈ 0`).   It is not possible to pick a nonzero `atol` automatically because it depends on the overall scaling (the \"units\") of your problem: for example, in `x - y ≈ 0`, `atol=1e-9` is an absurdly small tolerance if `x` is the [radius of the Earth](https://en.wikipedia.org/wiki/Earth_radius) in meters, but an absurdly large tolerance if `x` is the [radius of a Hydrogen atom](https://en.wikipedia.org/wiki/Bohr_radius) in meters.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> 0.1 ≈ (0.1 - 1e-10)\n",
       "true\n",
       "\n",
       "julia> isapprox(10, 11; atol = 2)\n",
       "true\n",
       "\n",
       "julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\n",
       "true\n",
       "\n",
       "julia> 1e-10 ≈ 0\n",
       "false\n",
       "\n",
       "julia> isapprox(1e-10, 0, atol=1e-8)\n",
       "true\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  isapprox(x, y; rtol::Real=atol>0 ? 0 : √eps, atol::Real=0, nans::Bool=false, norm::Function)\u001b[39m\n",
       "\n",
       "  Inexact equality comparison: \u001b[36mtrue\u001b[39m if \u001b[36mnorm(x-y) <= max(atol,\n",
       "  rtol*max(norm(x), norm(y)))\u001b[39m. The default \u001b[36matol\u001b[39m is zero and the default \u001b[36mrtol\u001b[39m\n",
       "  depends on the types of \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m. The keyword argument \u001b[36mnans\u001b[39m determines\n",
       "  whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "  For real or complex floating-point values, if an \u001b[36matol > 0\u001b[39m is not specified,\n",
       "  \u001b[36mrtol\u001b[39m defaults to the square root of \u001b[36meps\u001b[39m of the type of \u001b[36mx\u001b[39m or \u001b[36my\u001b[39m, whichever is\n",
       "  bigger (least precise). This corresponds to requiring equality of about half\n",
       "  of the significand digits. Otherwise, e.g. for integer arguments or if an\n",
       "  \u001b[36matol > 0\u001b[39m is supplied, \u001b[36mrtol\u001b[39m defaults to zero.\n",
       "\n",
       "  \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m may also be arrays of numbers, in which case \u001b[36mnorm\u001b[39m defaults to the\n",
       "  usual \u001b[36mnorm\u001b[39m function in LinearAlgebra, but may be changed by passing a\n",
       "  \u001b[36mnorm::Function\u001b[39m keyword argument. (For numbers, \u001b[36mnorm\u001b[39m is the same thing as\n",
       "  \u001b[36mabs\u001b[39m.) When \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m are arrays, if \u001b[36mnorm(x-y)\u001b[39m is not finite (i.e. \u001b[36m±Inf\u001b[39m or\n",
       "  \u001b[36mNaN\u001b[39m), the comparison falls back to checking whether all elements of \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m\n",
       "  are approximately equal component-wise.\n",
       "\n",
       "  The binary operator \u001b[36m≈\u001b[39m is equivalent to \u001b[36misapprox\u001b[39m with the default arguments,\n",
       "  and \u001b[36mx ≉ y\u001b[39m is equivalent to \u001b[36m!isapprox(x,y)\u001b[39m.\n",
       "\n",
       "  Note that \u001b[36mx ≈ 0\u001b[39m (i.e., comparing to zero with the default tolerances) is\n",
       "  equivalent to \u001b[36mx == 0\u001b[39m since the default \u001b[36matol\u001b[39m is \u001b[36m0\u001b[39m. In such cases, you should\n",
       "  either supply an appropriate \u001b[36matol\u001b[39m (or use \u001b[36mnorm(x) ≤ atol\u001b[39m) or rearrange your\n",
       "  code (e.g. use \u001b[36mx ≈ y\u001b[39m rather than \u001b[36mx - y ≈ 0\u001b[39m). It is not possible to pick a\n",
       "  nonzero \u001b[36matol\u001b[39m automatically because it depends on the overall scaling (the\n",
       "  \"units\") of your problem: for example, in \u001b[36mx - y ≈ 0\u001b[39m, \u001b[36matol=1e-9\u001b[39m is an\n",
       "  absurdly small tolerance if \u001b[36mx\u001b[39m is the radius of the Earth\n",
       "  (https://en.wikipedia.org/wiki/Earth_radius) in meters, but an absurdly\n",
       "  large tolerance if \u001b[36mx\u001b[39m is the radius of a Hydrogen atom\n",
       "  (https://en.wikipedia.org/wiki/Bohr_radius) in meters.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> 0.1 ≈ (0.1 - 1e-10)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox(10, 11; atol = 2)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> 1e-10 ≈ 0\u001b[39m\n",
       "\u001b[36m  false\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox(1e-10, 0, atol=1e-8)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?isapprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000643397144246e6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "syntax: \"$\" expression outside quote",
     "output_type": "error",
     "traceback": [
      "syntax: \"$\" expression outside quote",
      "",
      "Stacktrace:",
      " [1] top-level scope at C:\\Users\\Victor\\.julia\\packages\\IJulia\\DrVMH\\src\\kernel.jl:52"
     ]
    }
   ],
   "source": [
    "$a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     1.318 s (0.00% GC)\n",
       "  median time:      1.338 s (0.00% GC)\n",
       "  mean time:        1.339 s (0.00% GC)\n",
       "  maximum time:     1.361 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 4 entries:\n",
       "  \"Julia hand-written simd\" => 3.6455\n",
       "  \"Julia hand-written\"      => 10.9088\n",
       "  \"Julia built-in\"          => 3.6307\n",
       "  \"Python built-in\"         => 1318.4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python: `numpy` \n",
    "\n",
    "## Takes advantage of hardware \"SIMD\", but only works when it works.\n",
    "\n",
    "`numpy` is an optimized C library, callable from Python.\n",
    "It may be installed within Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Project.toml`\n",
      " \u001b[90m [8f4d0f93]\u001b[39m\u001b[92m + Conda v1.4.1\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `C:\\Users\\Victor\\.julia\\environments\\v1.4\\Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.add(\"Conda\")\n",
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y numpy` in root environment\n",
      "└ @ Conda C:\\Users\\Victor\\.julia\\packages\\Conda\\3rPhK\\src\\Conda.jl:113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Victor\\.julia\\conda\\3\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2020.4.5.2         |           py37_0         157 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         157 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                                 2020.4.5.1-py37_0 --> 2020.4.5.2-py37_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2020.4.5.2   | 157 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "Conda.add(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(o::PyObject, s::AbstractString)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.\"s\"` instead of `o[\"s\"]`.\n",
      "│   caller = top-level scope at In[43]:1\n",
      "└ @ Core In[43]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     9.155 ms (0.00% GC)\n",
       "  median time:      9.611 ms (0.00% GC)\n",
       "  mean time:        9.647 ms (0.00% GC)\n",
       "  maximum time:     13.033 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          518\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.00064339714361e6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"Julia hand-written simd\" => 3.6455\n",
       "  \"Python numpy\"            => 9.1554\n",
       "  \"Julia hand-written\"      => 10.9088\n",
       "  \"Julia built-in\"          => 3.6307\n",
       "  \"Python built-in\"         => 1318.4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Python, hand-written "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function py_sum at 0x00000000526D15E8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     1.705 s (0.00% GC)\n",
       "  median time:      1.713 s (0.00% GC)\n",
       "  mean time:        1.714 s (0.00% GC)\n",
       "  maximum time:     1.723 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_hand = @benchmark $sum_py($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000643397144246e6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 6 entries:\n",
       "  \"Julia hand-written simd\" => 3.6455\n",
       "  \"Python numpy\"            => 9.1554\n",
       "  \"Julia hand-written\"      => 10.9088\n",
       "  \"Python hand-written\"     => 1705.15\n",
       "  \"Julia built-in\"          => 3.6307\n",
       "  \"Python built-in\"         => 1318.4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Julia (built-in) \n",
    "\n",
    "## Written directly in Julia, not in C!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "sum(a::<b>AbstractArray</b>; <i>dims</i>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/44fa15b1502a45eac76c9017af94332d4557b251/base/reducedim.jl#L652\" target=\"_blank\">reducedim.jl:652</a>"
      ],
      "text/plain": [
       "sum(a::AbstractArray; dims) in Base at reducedim.jl:652"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     3.631 ms (0.00% GC)\n",
       "  median time:      3.746 ms (0.00% GC)\n",
       "  mean time:        3.799 ms (0.00% GC)\n",
       "  maximum time:     6.034 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1314\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 1 entry:\n",
       "  \"Julia built-in\" => 3.6307"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Julia (hand-written) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)   \n",
    "    s = 0.0 # s = zero(eltype(a))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     10.909 ms (0.00% GC)\n",
       "  median time:      10.947 ms (0.00% GC)\n",
       "  mean time:        11.055 ms (0.00% GC)\n",
       "  maximum time:     13.556 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          452\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand = @benchmark mysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 2 entries:\n",
       "  \"Julia hand-written\" => 10.9088\n",
       "  \"Julia built-in\"     => 3.6307"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Julia (hand-written w. simd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_simd (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_simd(A)   \n",
    "    s = 0.0 # s = zero(eltype(A))\n",
    "    @simd for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     3.646 ms (0.00% GC)\n",
       "  median time:      3.799 ms (0.00% GC)\n",
       "  mean time:        3.853 ms (0.00% GC)\n",
       "  maximum time:     10.057 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1296\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand_simd = @benchmark mysum_simd($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000643397143612e6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysum_simd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysum_simd(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"Julia hand-written simd\" => 3.6455\n",
       "  \"Julia hand-written\"      => 10.9088\n",
       "  \"Julia built-in\"          => 3.6307"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written simd\"] = minimum(j_bench_hand_simd.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia built-in..............3.6\n",
      "Julia hand-written simd.....3.6\n",
      "Python numpy................9.2\n",
      "Julia hand-written.........10.9\n",
      "Python built-in..........1318.4\n",
      "Python hand-written......1705.1\n"
     ]
    }
   ],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "212px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "2",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
